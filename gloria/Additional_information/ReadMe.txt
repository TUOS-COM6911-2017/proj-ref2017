In this section, I included the code files used to process the additional information, a 100-word paragraph for each submission in output, found in REF submission data. Two approaches were tested - Levenshtein distance and tfidf. Tfidf approach proved to provide better correlations by assigning a score for each word in additional information instead of comparing the entire 100-word string against each other. Based on tfidf, the number of higher-scored or 'unusual' words can be counted in each document provided that a tfidf threshold is defined above which the word is considered 'unusual'. This threshold varies from UOA to UOA due to different writing styles related to different disciplines of research studies. The final results were uploaded in subfolders which included addinfordict.pkl (additional information in paragraphs), addinforsummary.csv (number of submissions per institution, number of submissions with additional information per institution, and fraction of submissions with additional information), worddict.pkl (additional information in words), tfidfdict.pkl (tfidf score for each word), unusualwordcountdict.pkl (number of 'unusual' words per paragraph), correlations.csv (for a range of 20 tfidf thresholds, the Pearson correlation of unusual word count with: overall 4* scores and output 4* scores) and plots at best correlations.
